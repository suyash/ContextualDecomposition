{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "lstm_decomposition_demo.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7CI8T-Oxv3a",
        "colab_type": "text"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RUl59iOxtSM",
        "colab_type": "code",
        "outputId": "77272d73-5c47-46ef-fb53-1ae3861fdde8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!git clone \"https://github.com/suyash/ContextualDecomposition.git\" && mv ContextualDecomposition/cd ./cd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ContextualDecomposition'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 35 (delta 13), reused 33 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q_p9EfZxQpx",
        "colab_type": "code",
        "outputId": "3fd18656-61e2-402e-d947-a4754380a8b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!curl -L -o \"job_dir.zip\" \"https://drive.google.com/uc?export=download&id=13Uyub6pPWWS9USmj2WxAilPMoYFQZtCd\" && unzip -q -d \"job_dir\" \"job_dir.zip\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0     35      0 --:--:--  0:00:10 --:--:--    81\n",
            "100 21.6M    0 21.6M    0     0  1899k      0 --:--:--  0:00:11 --:--:-- 60.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eZJUKK70evz",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADDYjJZq0rtZ",
        "colab_type": "code",
        "outputId": "ef8c2090-329d-42bd-d91d-924995654e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGhV7mrdxBpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model  # pylint: disable=import-error\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, Input, LSTM  # pylint: disable=import-error\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from cd.cd import lstm_decomposition\n",
        "from cd.lstm import create_table, create_inv_table, preprocess_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBQ73NDPxBpi",
        "colab_type": "code",
        "outputId": "674ea0e9-f24f-4d59-d880-ea6cc1d40853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "model = tf.keras.models.load_model(\"job_dir/saved_model/best\")\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 128)         1831808   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,963,650\n",
            "Trainable params: 1,963,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eckB_JwkxBps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = np.load(\"job_dir/tokens.npy\")\n",
        "table = create_table(tokens)\n",
        "inv_table = create_inv_table(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVFs3an0xBpy",
        "colab_type": "text"
      },
      "source": [
        "### Process Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8EvMmnqxBp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = \"it 's easy to love robin tunney -- she is pretty and she can act -- but it gets harder and harder to understand her choices .\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGgdMoEUxBp7",
        "colab_type": "code",
        "outputId": "fd7ea87f-1032-411a-c8ce-e3f878b6715b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "inp = table.lookup(tf.constant(s.split()))\n",
        "inp = tf.expand_dims(inp, 0)\n",
        "inp"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 27), dtype=int32, numpy=\n",
              "array([[  12,    8,  396,    7,   82, 3814, 5186,   28,  281,    9,  313,\n",
              "           4,  281,   66,  590,   28,   22,   12,  283, 5449,    4, 5449,\n",
              "           7,  683,  115, 2049,    6]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WX57WJYxBqC",
        "colab_type": "text"
      },
      "source": [
        "### Generate Overall Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYcUo5ntxBqE",
        "colab_type": "code",
        "outputId": "b9040902-362e-4abf-c7b0-3106e5847edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = model.predict(inp)\n",
        "x = tf.math.softmax(x)\n",
        "x"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.72758025, 0.27241975]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuK66fAxxBqI",
        "colab_type": "text"
      },
      "source": [
        "$P(neg) = 0.84$, $P(pos) = 0.15$\n",
        "\n",
        "Now, decomposing and getting predictions for subsections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1gvo4A1xBqJ",
        "colab_type": "code",
        "outputId": "55014dd8-3136-402c-88af-e8a48e31ffc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "t = inv_table.lookup(inp[0]).numpy()\n",
        "list(enumerate(t))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, b'it'),\n",
              " (1, b\"'s\"),\n",
              " (2, b'easy'),\n",
              " (3, b'to'),\n",
              " (4, b'love'),\n",
              " (5, b'robin'),\n",
              " (6, b'tunney'),\n",
              " (7, b'--'),\n",
              " (8, b'she'),\n",
              " (9, b'is'),\n",
              " (10, b'pretty'),\n",
              " (11, b'and'),\n",
              " (12, b'she'),\n",
              " (13, b'can'),\n",
              " (14, b'act'),\n",
              " (15, b'--'),\n",
              " (16, b'but'),\n",
              " (17, b'it'),\n",
              " (18, b'gets'),\n",
              " (19, b'harder'),\n",
              " (20, b'and'),\n",
              " (21, b'harder'),\n",
              " (22, b'to'),\n",
              " (23, b'understand'),\n",
              " (24, b'her'),\n",
              " (25, b'choices'),\n",
              " (26, b'.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMXxHY4mxBqO",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare the Embedding generator for the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUb9VwXdxBqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_embedder(embed_dim, vocab_size):\n",
        "    seq = Input((None, ), dtype=\"int32\")\n",
        "    x = Embedding(\n",
        "        vocab_size,\n",
        "        embed_dim,\n",
        "    )(seq)\n",
        "    return tf.keras.Model(seq, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lXmp6clxBqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedder = prepare_embedder(128, 2 + len(tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQJTPlWqxBqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedder.set_weights(model.get_weights()[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x97SfTKlxBqe",
        "colab_type": "text"
      },
      "source": [
        "### Decomposing the prediction into the prediction for [0..15] and [16..26]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c2JiDkAxBqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, k, rk, b, dw, db = model.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxtXQoMtxBqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_inp = embedder(inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG-I_V1dxBqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_0_15, _ = lstm_decomposition(embed_inp, k, rk, b, 0, 15)\n",
        "pred_16_26, _ = lstm_decomposition(embed_inp, k, rk, b, 16, 26)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAOiY_AaxBqu",
        "colab_type": "code",
        "outputId": "d8193306-8990-495a-d305-a9ffbbe8ef12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.math.softmax(tf.matmul(pred_0_15, dw) + db)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.00325666, 0.9967434 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd64gk9TxBqz",
        "colab_type": "code",
        "outputId": "16141a51-9731-4e59-cd40-028012451a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.math.softmax(tf.matmul(pred_16_26, dw) + db)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.9955011 , 0.00449888]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN9S5whwxBq4",
        "colab_type": "text"
      },
      "source": [
        "decomposed prediction for __\"it 's easy to love robin tunney - she is pretty and she can act -\"__: $P(neg) = 0.005, P(pos) = 0.995$\n",
        "\n",
        "decomposed prediction for __\"but it gets harder and harder to understand her choices .\"__: $P(neg) = 0.996, P(pos) = 0.004$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9yTEzkh8Gcs",
        "colab_type": "text"
      },
      "source": [
        "### Individual Word Level Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pPBCCbZ8KGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "for i in range(27):\n",
        "    rel, _ = lstm_decomposition(embed_inp, k, rk, b, i, i)\n",
        "    pred = tf.math.softmax(tf.matmul(rel, dw) + db)\n",
        "    preds.append(pred.numpy().tolist()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9VmfVvk8lmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "20859679-930a-4231-9a74-af2cbbdf2f10"
      },
      "source": [
        "list(zip(t, preds))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(b'it', [0.4859467148780823, 0.5140532851219177]),\n",
              " (b\"'s\", [0.5432335138320923, 0.4567664563655853]),\n",
              " (b'easy', [0.4714977443218231, 0.5285022854804993]),\n",
              " (b'to', [0.5675297975540161, 0.4324701726436615]),\n",
              " (b'love', [0.14848144352436066, 0.8515185117721558]),\n",
              " (b'robin', [0.3177938759326935, 0.6822061538696289]),\n",
              " (b'tunney', [0.4475875198841095, 0.5524125099182129]),\n",
              " (b'--', [0.5062448978424072, 0.4937551021575928]),\n",
              " (b'she', [0.32740598917007446, 0.6725940108299255]),\n",
              " (b'is', [0.4344940185546875, 0.5655059814453125]),\n",
              " (b'pretty', [0.22031214833259583, 0.7796878218650818]),\n",
              " (b'and', [0.43068253993988037, 0.5693174600601196]),\n",
              " (b'she', [0.35035571455955505, 0.6496442556381226]),\n",
              " (b'can', [0.4265875518321991, 0.5734124779701233]),\n",
              " (b'act', [0.31614911556243896, 0.6838509440422058]),\n",
              " (b'--', [0.4745381474494934, 0.5254618525505066]),\n",
              " (b'but', [0.32750606536865234, 0.6724939346313477]),\n",
              " (b'it', [0.5035586357116699, 0.4964413642883301]),\n",
              " (b'gets', [0.546697199344635, 0.4533027708530426]),\n",
              " (b'harder', [0.9588047862052917, 0.04119517654180527]),\n",
              " (b'and', [0.3992045819759369, 0.6007953882217407]),\n",
              " (b'harder', [0.9551401138305664, 0.044859904795885086]),\n",
              " (b'to', [0.5107584595680237, 0.4892415404319763]),\n",
              " (b'understand', [0.8869693279266357, 0.11303067952394485]),\n",
              " (b'her', [0.18197977542877197, 0.8180201649665833]),\n",
              " (b'choices', [0.20139764249324799, 0.7986024022102356]),\n",
              " (b'.', [0.4168647825717926, 0.5831352472305298])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}